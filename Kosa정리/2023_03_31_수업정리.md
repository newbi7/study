## AI
```
strong AI
weak AI
-> Machine Learning (Data 기반 학습을 통해 predict)
1. 지도학습(supervised Learning)
2. 비지도학습(Unsupervised Learning)
3. 준지도 학습(Semi supervised Learning)
4. 강화학습  -> "알파고"

지도학습
->
1. Regression (통계에서 가져왔다.)
2. SVM (Support Vector Machine)
3. Decision Tres, Random Forest
4. KNN
5. Naive Bayes
6. Artificial Neutral Netwark(ANN)인공신경망 -> 발전 Deep Learning
7. K-Means, DBSCAN
8. Reinforcement Learning(강화학습)

1. Regression -> Linear Regression Model -> simple, multiple
2. Classfication -> Logistic Regression Model -> binary classfication, Multitional classification

Simple Lineur Regeession Model
```


다중 회귀분석(Multiple Regression Analysis)은 두 개 이상의 독립 변수(X1, X2, ... Xn)와 하나의 종속 변수(Y) 간의 관계를 분석하는 통계적 방법입니다. 다중 회귀분석은 회귀분석의 확장된 형태이며, 단순 회귀분석에서는 하나의 독립 변수만을 사용하지만, 다중 회귀분석에서는 여러 개의 독립 변수를 사용하여 종속 변수의 변동을 설명하는 모델을 만들어냅니다.

다중 회귀분석에서는 종속 변수와 독립 변수 간의 선형적인 관계를 가정하고, 이를 바탕으로 모델을 구축합니다. 모델은 다음과 같은 수식으로 나타낼 수 있습니다.

Y = β0 + β1X1 + β2X2 + ... + βnXn + ε

여기서 β0, β1, β2, ..., βn은 회귀계수(coefficient)이며, 독립 변수와 종속 변수 간의 관계를 나타내는 수치입니다. ε는 오차항(error term)으로, 모델로 예측할 수 없는 종속 변수의 변동을 설명하는 수치입니다.

회귀계수와 오차항에 대해 설명해줘

회귀계수(coefficient)는 다중 회귀분석에서 독립 변수와 종속 변수 간의 선형적인 관계를 나타내는 수치입니다. 각 독립 변수마다 하나의 회귀계수가 존재하며, 회귀계수는 해당 독립 변수의 기울기를 나타냅니다. 회귀계수는 다중 회귀분석에서 추정되며, 최소 제곱법을 사용하여 추정됩니다.

오차항(error term)은 다중 회귀분석에서 종속 변수의 예측값과 실제값 간의 차이를 설명하는 수치입니다. 즉, 모델로 예측할 수 없는 종속 변수의 변동을 설명합니다. 오차항은 회귀분석에서 추정된 모델로 모든 종속 변수의 변동을 설명하지는 못합니다. 따라서 오차항은 다른 요인들로 인해 설명되지 못한 종속 변수의 변동을 설명하는 것입니다.

회귀계수와 오차항은 모델을 구성하는 요소 중 하나로, 이들을 이용하여 모델을 구축하고 종속 변수의 값을 예측할 수 있습니다. 회귀분석에서는 모델이 얼마나 잘 맞는지를 측정하기 위해 R 제곱 값이나 조정된 R 제곱 값 등의 지표를 사용합니다.

```python
# 온도에 따른 오존량을 학습시켜 보아요!
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import SGD
import matplotlib.pyplot as plt

# Raw Data Loading
training_data = pd.read_csv('./data/ozone.csv')
display(training_data.head())

## 이상치도 같이 처리해 볼께요!
# 이상치처리
from scipy import stats
zscore_threshold = 1.8 # zscore outliers 임계값 (2.0이하가 optimal)

# outliers 출력.
# Temp에 대한 이상치(지대점) 확인
outliers = training_data['Temp'][(np.abs(stats.zscore(training_data['Temp'])) > zscore_threshold)]
print(outliers)    
# Temp에 대한 이상치(지대점) 제거한 결과
training_data = training_data.loc[~training_data['Temp'].isin(outliers)]
print(training_data.shape)  # (110, 2)

# Ozone에 대한 이상치(Outlier) 확인
outliers = training_data['Ozone'][(np.abs(stats.zscore(training_data['Ozone'])) > zscore_threshold)]
print(outliers)    
# Ozone에 대한 이상치 제거한 결과
training_data = training_data.loc[~training_data['Ozone'].isin(outliers)]
print(training_data.shape)  # (103, 2)



df = training_data[['Ozone', 'Temp']]
# 데이터 전처리를 실행해야 해요!
# 1. 제일먼저 결측치 처리를 해야 해요!( 삭제 )
df = df.dropna(how='any')

display(df.head(), df.shape)  # (116, 2)


df = df[['Ozone', 'Temp']]

# 데이터 전처리를 실행해야 해요!
# 1. 제일먼저 결측치 처리를 해야해요!(삭제)
df = df.dropna(how='any')
display(df.head(), df.shape) #(116,2)

# Training Data Set

x_data = df['Temp'].values.reshape(-1,1)
t_data = df['Ozone'].values.reshape(-1,1)

# 데이터 전처리!
from sklearn.preprocessing import MinMaxScaler
scaler_x = MinMaxScaler()
scaler_x.fit(x_data)  # scaler_x에게 x데이터가 가지고 있는 최대 최소값을 알려줘요!
x_data_norm = scaler_x.transform(x_data)

scaler_t = MinMaxScaler()
scaler_t.fit(t_data)  # scaler_x에게 x데이터가 가지고 있는 최대 최소값을 알려줘요!
t_data_norm = scaler_t.transform(t_data)


# Model
keras_model = Sequential()

# Layer
input_layer = Flatten(input_shape=(1,))
output_layer = Dense(1, activation='linear')

# Model에 layer를 추가
keras_model.add(input_layer)
keras_model.add(output_layer)

# Model 설정
keras_model.compile(optimizer=SGD(learning_rate=1e-4),
                    loss='mse')

# Model 학습
keras_model.fit(x_data_norm,
                t_data_norm,
                epochs=2000,
                verbose=0)


# 평가가 잘 이루어졌다고 치고!!!
# 모델이 잘 만들어졌으면 예측해보아요!
scaled_data = scaler_x.transform([[62]])
result = keras_model.predict(scaled_data)  # 화씨 62인 경우 오존량은 얼마인가요?
print(result)   # [[40.502384]] => [[7.6789017]] => [0.17523915]]
# 이 0.17523915은 오존값인데 이게 scaling되어 있는 값이예요!
# 그렇기 때문에 원래 오존값을 계산하려면.. 원복시켜야해요!
real_result = scaler_t.inverse_transform(scaled_data)

print(real_result) # [[21.875]]
# 결과가 나오긴 했는데 이게 정답인지 아닌지..잘 예측했는지 알 수 없어요!

# 그림으로 확인해 보아요!
plt.scatter(x_data_norm, t_data_norm)

weight, bias = output_layer.get_weights()

plt.plot(x_data_norm, x_data_norm*weight + bias, color='m')

plt.show()


# 잘 만들어진 라이브러리를 이용하여 정답에 가까운 값을 알아볼거에요
# sklearn이라는 모듈을 이용하자
from sklearn import linear_model

# x_data, t_data는 이미 가지고 있어요
# model을 만들어 보아요
sklearn_model = linear_model.LinearRegression()

# 학습 진행
sklearn_model.fit(x_data, t_data)

# 예측!
result_sklearn = sklearn_model.predict([[62]])
print(result_sklearn) #[[3.58411393]]

# 눈으로 확인해 보아요!! 산점도(scatter)와 직선(model)으로 알아 보아요!
plt.scatter(x_data, t_data)

weight = sklearn_model.coef_
bias = sklearn_model.intercept_

plt.plot(x_data, x_data*weight + bias, color='r')

plt.show()

# 이러한 차이는 데이터 전처리떄문에 그렇다.

# 기억해야 하는 전처리 과정은 3개이다. ( 더 많고 수학적 접근을 해야 한다.)
# 1. 결측치 처리 (이건 했어요! 그냥 냅다 삭제했어요)
# 2. 이상치 처리 (처리해야한다.)
# 3. 정규화 (Normalization) - 반드시 해야 해요!
#     min-max scaling을 이용할 거에요! 최대값 1 최소값 0사이의 값으로 값을 변환
```
