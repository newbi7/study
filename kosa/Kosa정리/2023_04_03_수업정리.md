## Lineur Regeession (선형회귀)
```
독립 변수 1개   
-> y (예측값) = w (가중치) x (독립변수)  +   b (보정치) 
     
독립변수 3개   
```
$y = w_1x_1 + w_2x_2 + w_3x_3 + b$   

|X1(온도) | X2(태양광) | X3(바람) | t(오존량) |
|----|----|----|---|
| 1  | 2  | 3  |  |
| 5  | 6  | 7  |  |
| 9  | 10 | 11 |  |
```
5x3 행렬과 5x1행렬(오존량)의 결과값이 같으려면??

2차원행렬을 만드려면 일일히 수식을 적어야 했지만 keras_model을 씀으로써 편리해졌다.
````
```python
# 다중선형회귀를 구현해 보아요!
# 오존데이터를 가지고 모델을 만들어 볼꺼에요!

# 1. 필요한 module을 불러들여요!
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam

# 2. Raw Data Loading
raw_data=pd.read_csv('./data/ozone.csv')
display(raw_data.head(), raw_data.shape) #(153, 6)

# 결측치 처리! => 그냥 삭제할게요
raw_data = raw_data.dropna(how='any')
display(raw_data.head(), raw_data.shape) #(111, 6)

# 이상치는 처리하지 않는다.

# 정규화는 진행해야 한다. MinMaxScaler()로 진행할것이다.
scaler_x = MinMaxScaler()
scaler_t = MinMaxScaler()

# scaler한테 최대값과 최소값을 알려줘야 정보를 가지고 정규화를 진행할 수 있다.
scaler_x.fit(raw_data[['Solar.R', 'Wind', 'Temp']].values)
scaler_t.fit(raw_data['Ozone'].values.reshape(-1,1))

# 3. Training Data Set
x_data = scaler_x.transform(raw_data[['Solar.R', 'Wind', 'Temp']].values)
# print(x_data)
t_data = scaler_t.transform(raw_data[['Ozone']].values.reshape(-1,1))
# print(t_data)

# Model
model = Sequential()

# Layer 추가
model.add(Flatten(input_shape=(3,)))
model.add(Dense(1, activation='linear'))

# Model 설정
model.compile(optimizer=Adam(learning_rate=1e-4),
             loss='mse')

# Model 학습
model.fit(x_data,
          t_data,
          epochs=2000,
         verbose=0)
# 우리 모델이 잘 만들어졌는 지 평가해야하는데 적당한 기준이 없다.
# 지금은 넘어가자

# 모델이 완성 됬다고 생각되면 예측작업에 들어간다.
# 예측하고 싶은건 태양광 150, 바랍 10, 온도 80일 경우 오존량 예측
predict_data = np.array([[150.0, 10.0, 80.0]])
scaled_predict_data = scaler_x.transform(predict_data)
# print(scaled_predict_data)
result = model.predict(scaled_predict_data)
# print(result)  #[[0.33035934]]
final_result = scaler_t.inverse_transform(result)
print(final_result)
```
```Python
좋습니다! 각 부분을 자세하게 설명해드리도록 하겠습니다.

필요한 라이브러리 import
javascript
Copy code
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam
numpy: 파이썬에서 대규모 다차원 배열과 행렬을 처리하는 라이브러리입니다.
pandas: 파이썬에서 데이터를 처리하는 라이브러리입니다.
MinMaxScaler: 데이터 정규화를 위한 클래스입니다.
Sequential: 모델을 생성하는 클래스입니다.
Flatten: 다차원 배열을 1차원으로 변환하는 레이어 클래스입니다.
Dense: 완전 연결 층을 생성하는 레이어 클래스입니다.
Adam: 경사 하강법을 사용하는 최적화 알고리즘입니다.
Raw Data Loading
scss
Copy code
raw_data=pd.read_csv('./data/ozone.csv')
display(raw_data.head(), raw_data.shape) #(153, 6)

raw_data = raw_data.dropna(how='any')
display(raw_data.head(), raw_data.shape) #(111, 6)
pandas의 read_csv() 함수를 사용하여 './data/ozone.csv' 파일을 읽어옵니다.
head() 함수를 사용하여 데이터 상위 5개를 출력합니다.
dropna() 함수를 사용하여 결측치를 처리합니다. how='any'를 사용하여 결측치가 하나라도 있으면 해당 행을 삭제합니다.
데이터 정규화
lua
Copy code
scaler_x = MinMaxScaler()
scaler_t = MinMaxScaler()

scaler_x.fit(raw_data[['Solar.R', 'Wind', 'Temp']].values)
scaler_t.fit(raw_data['Ozone'].values.reshape(-1,1))

x_data = scaler_x.transform(raw_data[['Solar.R', 'Wind', 'Temp']].values)
t_data = scaler_t.transform(raw_data[['Ozone']].values.reshape(-1,1))
MinMaxScaler() 클래스를 사용하여 데이터를 정규화합니다.
scaler_x는 입력 데이터를 정규화하기 위한 객체이며, scaler_t는 출력 데이터를 정규화하기 위한 객체입니다.
fit() 함수를 사용하여 scaler_x와 scaler_t에 최대값과 최소값을 알려줍니다.
transform() 함수를 사용하여 x_data와 t_data를 정규화합니다.
모델 구성
less
Copy code
model = Sequential()

model.add(Flatten(input_shape=(3,)))
model.add(Dense(1, activation='linear'))

model.compile(optimizer=Adam(learning_rate=1e-4),
             loss='mse')
Sequential() 함수를 사용하여 모델을 생성합니다.
add() 함수를 사용하여 모델에 레이어를 추가합니다.
Flatten() 함수를 사용하여 다차원 배열을 1차원으로 변환합니다. input_shape=(3,)으로 입력 데이터의 차원을 지정해줍니다.
Dense() 함수를 사용하여 완전 연결 층을 생성합니다. 첫 번째 인자는 출력 뉴런의 수를 의미합니다


Model
모델을 만들기 위해 Sequential() 함수를 사용하여 빈 모델을 만듭니다. Sequential 모델은 층(layer)을 순차적으로 쌓아가는 모델입니다. 이 모델은 단순한 선형 회귀 모델로 구성되어 있습니다.
Layer 추가: 모델에 층을 추가합니다. 우선, input_shape를 정의하기 위해 3차원 벡터로 변환합니다(Flatten). 그 다음으로, Dense 층을 추가합니다. 이 층은 선형 회귀 모델을 구성하는 핵심 층입니다. 이 층은 활성화 함수를 지정하지 않았으므로, 선형 회귀 모델이 됩니다.

Model 설정: 컴파일 메서드를 사용하여 모델을 설정합니다. 여기서는 Adam 옵티마이저를 사용하고, 평균 제곱 오차(mse)를 손실 함수(loss)로 사용합니다.

Model 학습
모델을 학습시키기 위해 fit() 메서드를 사용합니다. 여기서는 정규화된 x_data와 t_data를 사용합니다. epochs는 전체 데이터셋에 대한 학습 횟수를 나타냅니다. verbose는 학습 진행 상황을 출력하는 옵션입니다.

Model 예측
학습된 모델을 사용하여 새로운 데이터에 대한 예측을 수행합니다. 예측하고자 하는 데이터를 predict_data에 저장합니다. 이 데이터를 정규화하기 위해 scaler_x를 사용하여 스케일링한 후, model.predict() 메서드를 사용하여 예측값을 출력합니다. 마지막으로, scaler_t를 사용하여 역정규화하여 최종 예측값을 출력합니다.

즉, 이 코드는 태양광, 바람, 온도 데이터를 기반으로 오존량을 예측하는 간단한 선형 회귀 모델을 만들고, 이 모델을 학습하여 새로운 데이터에 대한 예측값을 출력하는 코드입니다.
```
```
1. Multiple Linear Regression

2. (Multiple) Logistic Regression (Data(종속변수의 형태가 바뀐다.)가 바뀌었다.)

binary classfication
-> 이 문제를 처음에는 Linear Regression으로 해결하려고 노력해 봤지만 안된다!!
-> 그럼 어떻게 하면 될까요??
```
$sigmoid(x) = 1 / (1 + exp(-x))$
```
->Linear Regression Model
```
$sigmoid(x) = 1 / (1 + exp(-x=w+b))$ = Logistic Regression
```
선형 회귀와 로지스틱 회귀는 모두 입력값과 가중치의 선형 조합을 사용합니다. 하지만 선형 회귀는 연속적인 실수값을 예측하는 회귀(Regression) 문제에 적합하고, 로지스틱 회귀는 이진 분류(Binary Classification) 문제에 적합합니다. 

1. 수식
선형 회귀 수식
선형 회귀 모델의 수식은 다음과 같습니다.

y = w^Tx + b
여기서 w는 가중치 벡터(weights vector)이고, x는 입력값(feature) 벡터입니다. b는 편향(bias)입니다. 이 식은 입력값과 가중치의 선형 조합으로 실수값을 예측합니다.

로지스틱 회귀 수식
로지스틱 회귀 모델의 수식은 다음과 같습니다.

y = sigmoid(w^Tx + b)
여기서 sigmoid 함수는 다음과 같이 정의됩니다.

sigmoid(x) = 1 / (1 + exp(-x))
이 함수는 입력값(x)을 0과 1 사이의 값으로 변환하여 이진 분류 문제에서 사용됩니다. sigmoid 함수를 사용하여 입력값의 선형 조합을 0과 1 사이의 값으로 변환한 뒤, 이진 분류 문제에서는 0.5를 기준으로 0 또는 1로 분류합니다.

2. 예측값
선형 회귀 예측값
선형 회귀 모델의 예측값은 입력값과 가중치의 선형 조합으로 계산됩니다. 이 값은 연속적인 실수값입니다.

로지스틱 회귀 예측값
로지스틱 회귀 모델의 예측값은 sigmoid 함수를 사용하여 입력값과 가중치의 선형 조합을 0과 1 사이의 값으로 변환한 값입니다. 이 값은 해당 클래스에 속할 확률로 해석할 수 있습니다. 예를 들어, sigmoid 함수의 결과값이 0.7이라면 해당 입력값이 양성 클래스에 속할 확률이 70%라는 것을 의미합니다.

3. 손실 함수
선형 회귀 손실 함수
선형 회귀 모델의 손실 함수는 보통 Mean Squared Error (MSE)를 사용합니다. MSE는 예측값과 실제값의 차이를 제곱한 값들의 평균입니다.

MSE = 1/n * Σ(y_pred - y_true)^2
여기서 y_pred는 예측값이고, y_true는 실제값입니다.

로지스틱 회귀 손실 함수
로지스틱 회귀 모델의 손실 함수는 보통 Cross Entropy Loss를 사용합니다. Cross Entropy Loss는 이진 분류 문제에서 예측값과 실제값 사이의 오차를 계산합니다.

Cross Entropy Loss = -1/n * Σ(y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred))
여기서 y_pred는 예측값으로, y_true는 실제값입니다.

결론
선형 회귀와 로지스틱 회귀는 모두 입력값과 가중치의 선형 조합을 사용하지만, 문제의 성격에 따라 적합한 모델을 선택해야 합니다. 이진 분류 문제에서는 로지스틱 회귀 모델과 Cross Entropy Loss 함수를 사용하는 것이 일반적입니다.
```
```python
# Logistic Regression을 구현해 보아요!
# Binary Classification(이항분류)

# 처음은 당연히 필요한 모듈 불러들이는것부터 시작
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler # 정규화
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam

# Raw Data Loading + 데이터 전처리
# 3가지만 진행
# 1. 결측치
# 2. 이상치
# 3. 정규화

df = pd.read_csv('./data/admission.csv')
# display(df.head(), df.shape) # (400, 4)
# print(df.info()) # 확인해보니 결측치는 존재하지 않는다 .-> 처리할 필요 없다.

# 이상치 처리인데.. 사실 이 데이터는 이상치가 존재한다.
# 여러가지 방법이 있는데 대표적인건 2가지이다.
# 1. Tukey Fence(4분위를 이용하는 방법)
# 2. Z-Score 방식(정규분포를 이용하는 방법)

from scipy import stats

zscore_threshold = 2.0 # zscore outliers 임계값 (2.0이하가 optimal)


for col in df.columns:
    outliers = df[col][(np.abs(stats.zscore(df[col])) > zscore_threshold)]
    df = df.loc[~df[col].isin(outliers)]
    
print(df.shape)  # (382, 4)

# 마지막 정규화를 진행해야 해요!
scaler = MinMaxScaler()
scaler.fit(df[['gre', 'gpa']].values)

from sklearn.model_selection import train_test_split

# Training Data Set
x_data = scaler.transform(df[['gre', 'gpa']].values)
t_data = df['admit'].values.reshape(-1,1)

x_data_train, x_data_test, t_data_train, t_data_test = \
train_test_split(x_data,
                t_data,
                test_size=0.2)

# Model
model = Sequential()

# Model에 Layer 추가
model.add(Flatten(input_shape=(2, )))
model.add(Dense(1, activation='sigmoid'))

# Model 설정
model.compile(optimizer=Adam(learning_rate=1e-3),
              loss='binary_crossentropy',
             metrics=['accuracy'])

# Model 학습
model.fit(x_data_train,
         t_data_train,
         epochs = 500,
          validation_split=0.2,
         verbose = 1)

# 잘 만든 모델인지 평가를 해보자
# 위에서 여러방법(하이퍼 파라미터를 수정하는 방법) 모델을 완성시켰으면
# 최종적으로 우리 모델의 정확도를 계산
eval_result = model.evaluate(x_data_train, t_data_train) # 마지막평가


# 평가가 잘 끝났으면 예측해야한다.
# 성적이 550, 3.5 일때 합격여부를 알아보아요!
predict_data = np.array([[550.0,3.5]])
scaled_predict_data = scaler.transform(predict_data)
result = model.predict(scaled_predict_data)
print(result)
```
Logistic Regression으로 넘어가면서 Evaluuation(평가) 얘기가 나와요~~
1. 방법(Data관점)
Training Data Set
(약 400개) -> 
      7           |        3
Training Data Set |  Test Data Set(딱 한번 사용)

Training Data Set, Validation data Set, Test data Set
```
머신 러닝에서, 학습 데이터셋(training dataset)은 모델을 학습시키는 데 사용되는 데이터 샘플의 집합입니다. 이것은 모델이 일반화를 수행하고 새로운 데이터를 예측할 수 있는 능력을 향상시키는 데 사용됩니다.

하지만, 학습 데이터만 사용해서 모델을 테스트한다면, 모델이 학습 데이터를 외워서 테스트 데이터에 대해서는 정확한 예측을 수행하지 못할 수 있습니다. 따라서, 학습한 모델의 성능을 평가하기 위해서는 테스트 데이터셋(test dataset)이 필요합니다. 테스트 데이터셋은 모델이 본 적이 없는 새로운 데이터 샘플의 집합입니다.

그러나, 모델의 학습 과정에서 다양한 하이퍼파라미터 값을 시도하거나, 모델 구조를 변경하는 등의 실험을 수행할 때에도 모델의 성능을 정량화하고 비교하기 위한 지표가 필요합니다. 이를 위해, 검증 데이터셋(validation dataset)을 사용합니다. 검증 데이터셋은 학습 데이터셋과 테스트 데이터셋의 중간에 위치하며, 모델을 학습하면서 검증 데이터셋을 사용해서 성능을 평가합니다. 이를 통해, 모델의 성능을 개선하기 위한 하이퍼파라미터 최적화 등을 수행할 수 있습니다.

따라서, 일반적으로 머신 러닝에서는 학습 데이터셋, 검증 데이터셋, 테스트 데이터셋을 나누어 사용합니다. 이렇게 나누어진 데이터셋은 각각 모델 학습, 모델 성능 평가, 모델 검증 등에 사용됩니다.
```

2. 평가기준(Metric)

Confusion Matrix
->
|                       실제정답(t)                
| Actual \ Predicted | True(1)          | False(0)   |
|--------------------|-------------|-------------|
| True         | True Positive (TP) | False Positive (FN) |
| False           | False Negative (FP)| True Negative (TN)  |


Metrics
Accuary (정확도)
= TP + TN -> 맞춘거 / TP + FN + FP + TN -> 모든경우

연습문제 -> Titanic (binary classification)
        -> "kaggle"

Data Set -> 학습데이터로 변형해야해요!
-> Model 학습 -> Model 완성 (test.csv 입력 ) -> (출력) File로 만들어서 keggle upload


```python
import numpy as np
import pandas as pd

# Raw Data Loading
train = pd.read_csv('./data/titanic/train.csv')

# display(train.head())

# 제일 먼저 해야할건.. 종속변수는 Survived
# 독립변수 중 종속변수에 영향을 미치지 않는 것들을 찾아내야 해요!
# 필요없는 독립변수는 제거할거에요!

train.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'], axis=1, inplace=True)

# display(train.head())

# 성별이 글자로 되어 있어요 당연히 숫자로 변경해야 해요!
my_map = { 'male': 0, 'female': 1}
train['Sex'] = train['Sex'].map(my_map)

# 가족처리
train['Family'] = train['SibSp'] + train['Parch']
train.drop(['SibSp', 'Parch'], axis=1, inplace=True)
# display(train.head())

# Embarked에는 결치값이 3개가 있다.
# 지우기보다는 값을 대체해서 사용하는게 좋다.
# 가장 빈도가 많은걸 찾아서 대체하는게 좋아요
train['Embarked'] = train['Embarked'].fillna('Q')
# display(train.info())
my_embarked_map = { 'C': 0, 'S' : 1, 'Q' : 2 }
train['Embarked'] = train['Embarked'].map(my_embarked_map)
# display(train.head())

# Age는 나이인데.. NaN이 너무 많다. 삭제는 힘들고 NaN을 다른 값으로 대체
# => 평균을 구해서 대체하면 좋을것 같다.
train['Age']=train['Age'].fillna(train['Age'].mean())
# display(train.head())

# 나이를 살펴보니 연속적인 숫자값보다 구간값으로 사용하면 더 좋을 것 같아요
train.loc[train['Age'] < 8, 'Age'] = 0
train.loc[(train['Age'] >= 8) & (train['Age'] < 20), 'Age'] = 1
train.loc[(train['Age'] >= 20) & (train['Age'] < 65), 'Age'] = 2
train.loc[train['Age'] >= 65, 'Age'] = 3
display(train.head())

# Training Data Set
x_data = train.drop('Survived', axis=1, inplace=False).values
t_data = train['Survived'].values.reshape(-1,1)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam

# Model
model = Sequential()

# Model에 Layer 추가
model.add(Flatten(input_shape=(5, )))
model.add(Dense(1, activation='sigmoid'))

# Model 설정
model.compile(optimizer=Adam(learning_rate=1e-3),
              loss='binary_crossentropy',
             metrics=['accuracy'])

# Model 학습
model.fit(x_data,
         t_data,
         epochs = 500,
          validation_split=0.2,
         verbose = 1)

# 모델을 완성했어요!
# Kaggle에서 제공해준 test.csv를 이용해서 prediction을 해야해요!
# test.csv를 읽어들여서 이 데이터를 다시 변형시켜야 해요!
# machine learning model에 입력으로 넣어야 하기 때문이다.
# 결과가 나오면 file을 만들어서 Kaggle에 제출해서 모델의 정확도를 측정 받으면 된다.
```